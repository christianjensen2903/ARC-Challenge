{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={'refusal': None} response_metadata={'finish_reason': 'stop', 'logprobs': None} id='run-f01c0b2d-0b50-4619-9e6c-ebd32fe00124-0' usage_metadata={'input_tokens': 24, 'output_tokens': 14, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages, n=2)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='The capital of France is Paris.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'finish_reason': 'stop', 'logprobs': None}, id='run-9541ad8f-4cef-4dc6-96c5-e374dd4e4664-0', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})), ChatGeneration(text='The capital of France is Paris.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'logprobs': None}, id='run-9541ad8f-4cef-4dc6-96c5-e374dd4e4664-1', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}))]], llm_output={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 14, 'total_tokens': 28, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_e2bde53e6e'}, run=[RunInfo(run_id=UUID('9541ad8f-4cef-4dc6-96c5-e374dd4e4664'))], type='LLMResult')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate([[HumanMessage(content=\"What is the capital of France?\")]], n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "2\n",
      "[[7 9 7 9 7 9]\n",
      " [4 3 4 3 4 3]\n",
      " [7 9 7 9 7 9]\n",
      " [4 3 4 3 4 3]\n",
      " [7 9 7 9 7 9]\n",
      " [4 3 4 3 4 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform(grid: np.ndarray) -> np.ndarray:\n",
    "    # Get the dimensions of the input grid\n",
    "    rows, cols = grid.shape\n",
    "    \n",
    "    # Create an output grid of size 6x6\n",
    "    output = np.empty((6, 6), dtype=object)\n",
    "    \n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            # Fill the output grid with alternating colors based on the input grid\n",
    "            output[i, j] = grid[i % rows, j % cols]\n",
    "    \n",
    "    return output\n",
    "\n",
    "grid = np.array([[7, 9], [4, 3]])\n",
    "output = transform(grid)\n",
    "print(output.dtype)\n",
    "print(output.ndim)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
