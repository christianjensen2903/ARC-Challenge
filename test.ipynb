{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={'refusal': None} response_metadata={'finish_reason': 'stop', 'logprobs': None} id='run-f01c0b2d-0b50-4619-9e6c-ebd32fe00124-0' usage_metadata={'input_tokens': 24, 'output_tokens': 14, 'total_tokens': 38, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages, n=2)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='The capital of France is Paris.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'finish_reason': 'stop', 'logprobs': None}, id='run-9541ad8f-4cef-4dc6-96c5-e374dd4e4664-0', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})), ChatGeneration(text='The capital of France is Paris.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'logprobs': None}, id='run-9541ad8f-4cef-4dc6-96c5-e374dd4e4664-1', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}))]], llm_output={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 14, 'total_tokens': 28, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_e2bde53e6e'}, run=[RunInfo(run_id=UUID('9541ad8f-4cef-4dc6-96c5-e374dd4e4664'))], type='LLMResult')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate([[HumanMessage(content=\"What is the capital of France?\")]], n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "len(list(string.ascii_uppercase) + ['A' + c for c in list(string.ascii_uppercase)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "2\n",
      "[[7 9]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "code = \"\"\"\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "\n",
    "def transform(grid: np.ndarray) -> np.ndarray:\n",
    "    teal_color = 2  # ðŸŸ¢\n",
    "    fill_color = 0  # âšªï¸\n",
    "\n",
    "    # Find the connected components of the teal color\n",
    "    labeled_array, num_features = label(grid == teal_color)\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        coords = np.argwhere(labeled_array == i)\n",
    "        if coords.size > 0:\n",
    "            # Create a mask for the region\n",
    "            min_row, min_col = np.min(coords, axis=0)\n",
    "            max_row, max_col = np.max(coords, axis=0)\n",
    "            \n",
    "            # Fill interior cells with fill_color\n",
    "            grid[min_row+1:max_row, min_col+1:max_col] = fill_color\n",
    "\n",
    "    return grid\n",
    "\"\"\"\n",
    "\n",
    "exec(code)\n",
    "\n",
    "grid = np.array([[7, 9], [4, 3]])\n",
    "output = transform(grid)\n",
    "print(output.dtype)\n",
    "print(output.ndim)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
